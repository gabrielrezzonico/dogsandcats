{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Simple CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We are going to define a simple Convolutional Network and we are going to train it from scrath on the dataset. The results of this model is going to be our benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We are going to use Keras library with tensorflow as a backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Common configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (360,404) # The dimensions to which all images found will be resized.\n",
    "BATCH_SIZE = 32\n",
    "NUMBER_EPOCHS = 8\n",
    "\n",
    "TENSORBOARD_DIRECTORY = \"../logs/simple_model/tensorboard\"\n",
    "TRAIN_DIRECTORY = \"../data/train/\"\n",
    "VALID_DIRECTORY = \"../data/valid/\"\n",
    "\n",
    "NUMBER_TRAIN_SAMPLES = 20000\n",
    "NUMBER_VALIDATION_SAMPLES = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "\n",
    "inputs = Input(shape = (IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "\n",
    "# First CNN Layer\n",
    "x = Convolution2D(16, (3, 3), \n",
    "                  activation='relu', \n",
    "                  data_format=\"channels_last\", \n",
    "                  kernel_initializer=\"he_uniform\")(inputs)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(3, 3), \n",
    "                 strides=(2, 2), \n",
    "                 data_format=\"channels_last\")(x)\n",
    "\n",
    "# Second CNN Layer\n",
    "x = Convolution2D(32, (3, 3), \n",
    "                  activation='relu', \n",
    "                  data_format=\"channels_last\", \n",
    "                  kernel_initializer=\"he_uniform\")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), \n",
    "                 strides=(2, 2), \n",
    "                 data_format=\"channels_last\")(x)\n",
    "\n",
    "# Third CNN Layer\n",
    "x = Convolution2D(64, (3, 3), \n",
    "                  activation='relu', \n",
    "                  data_format=\"channels_last\", \n",
    "                  kernel_initializer=\"he_uniform\")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), \n",
    "                 strides=(2, 2), \n",
    "                 data_format=\"channels_last\")(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(128, activation='relu',kernel_initializer=\"he_uniform\")(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model arquitecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We have the following model arquitecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 360, 404, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 358, 402, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 178, 200, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 176, 198, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 88, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 86, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 43, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 132096)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16908416  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 16,932,129.0\n",
      "Trainable params: 16,932,129.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Keras callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to define two callbacks that are going to be called in the training. EarlyStopping to stop the training if its not getting better. And a tensorboard callback to log information to be used by tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging basic info to be used by TensorBoard to ../logs/simple_model/tensorboard. To see this log run:\n",
      "tensorboard --logdir=../logs/simple_model/tensorboard\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Early stop in case of getting worse\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', patience = 3, verbose = 0)\n",
    "\n",
    "#TensorBoard\n",
    "# run tensorboard with tensorboard --logdir=/full_path_to_your_logs\n",
    "tensorboard_path = TENSORBOARD_DIRECTORY\n",
    "tensorboard_logger = TensorBoard(log_dir=tensorboard_path, histogram_freq=0, write_graph=False, write_images=False)\n",
    "print('Logging basic info to be used by TensorBoard to {}. To see this log run:'.format(tensorboard_path))\n",
    "print('tensorboard --logdir={}'.format(tensorboard_path))\n",
    "\n",
    "callbacks = [early_stop, tensorboard_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OPTIMIZER_LEARNING_RATE = 1e-2\n",
    "OPTIMIZER_DECAY = 1e-4  # LearningRate = LearningRate * 1/(1 + decay * epoch)\n",
    "OPTIMIZER_MOMENTUM = 0.89\n",
    "OPTIMIZER_NESTEROV_ENABLED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "optimizer = SGD(lr=OPTIMIZER_LEARNING_RATE, \n",
    "          decay=OPTIMIZER_DECAY, \n",
    "          momentum=OPTIMIZER_MOMENTUM, \n",
    "          nesterov=OPTIMIZER_NESTEROV_ENABLED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizer, \\\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "## train generator with shuffle but no data augmentation\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_batch_generator =  train_datagen.flow_from_directory(TRAIN_DIRECTORY, \n",
    "                                                 target_size = IMAGE_SIZE,\n",
    "                                                 class_mode = 'categorical', \n",
    "                                                 batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "## train generator with shuffle but no data augmentation\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "valid_batch_generator =  validation_datagen.flow_from_directory(VALID_DIRECTORY, \n",
    "                                                 target_size = IMAGE_SIZE,\n",
    "                                                 class_mode = 'categorical', \n",
    "                                                 batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    }
   ],
   "source": [
    "# fine-tune the model\n",
    "hist = model.fit_generator(\n",
    "        train_batch_generator,\n",
    "        steps_per_epoch=NUMBER_TRAIN_SAMPLES/BATCH_SIZE,\n",
    "        epochs=NUMBER_EPOCHS,  # epochs: Integer, total number of iterations on the data.\n",
    "        validation_data=valid_batch_generator,\n",
    "        validation_steps=NUMBER_VALIDATION_SAMPLES/BATCH_SIZE,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
